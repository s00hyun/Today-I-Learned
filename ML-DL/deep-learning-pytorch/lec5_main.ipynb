{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec5_main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWRNXlqnLsGngCp8aqEQnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s00hyun/Today-I-Learned/blob/master/ML-DL/deep-learning-pytorch/lec5_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C55aPdalOsSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e749f1e6-163e-443c-e64a-61b9203026a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMpxLmyma7V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install import_ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLv5_GvXbBDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import import_ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfP0ZsEpg9E7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fa80764-dc54-4f32-dcd6-d6f7c8cadc05"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7756P5Wp1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e92f87ac-94e1-4d9b-a367-cbff9b31f4f8"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/딥러닝수업"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/딥러닝수업\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4WIaB_khMaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e567bec-c8eb-42bf-dbb8-d8df5b091236"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/딥러닝수업\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZGaBMlgrCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9da0c8c9-0c83-4ed3-f968-b99e8f7e9f60"
      },
      "source": [
        "!ls -l lec5_model.ipynb"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 5687 Apr 14 06:35 lec5_model.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eei7ITJWzJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JtCpxm5W-UH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fef14c8-609f-48ee-c35a-bfbf10bb9cdc"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"current device:\", device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLm_bP4bX3hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs, num_classes, batch_size, learning_rate = 10, 10, 16, 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY0SOzAhYA1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lec5_model import ConvNet, AlexNet, VGGNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coa7M-XdiGIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network = 'alexnet'  # simple-cnn, alexnet, vgg-16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkC8ONBbiWj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if network == 'simple-cnn':\n",
        "  model = ConvNet().to(device)\n",
        "  composed_transforms = transforms.Compose([transforms.Resize((32, 32)),  # 해당 네트워크에 맞게 input size 조정\n",
        "                                            # 텐서 Type으로 변환\n",
        "                                            # Type: PIL -> torch.Tensor\n",
        "                                            # Pixel value: [0, 255] -> [0, 1]\n",
        "                                            transforms.ToTensor(),   \n",
        "                                            # (R채널 Mean, G채널 Mean, B채널 Mean), (R채널 Std, G채널 Std, B채널 Std)\n",
        "                                            # Pixel value를 [0, 1]에서 [-1, 1]로 변환함\n",
        "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "elif network == 'alexnet':\n",
        "  model = AlexNet(num_classes=num_classes).to(device)\n",
        "  composed_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "elif network == 'vgg-16':\n",
        "  model = VGGNet(num_classes=num_classes).to(device)\n",
        "  composed_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DzvLo2ZjnE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "1c58d670-e6f4-4010-a53d-6ce5fbbccec0"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExY-NGWij7zq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b5c8991-9dd9-47f0-dcd7-0c039354507e"
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=composed_transforms, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=composed_transforms)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwwzFAnXk2ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEwCRqcvlHTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "e497c00c-f125-406b-97dc-abcccea2fb86"
      },
      "source": [
        "# 모델에 학습 데이터를 입력 -> 예측 레이블 산출, 정답 레이블과 비교 -> 모델의 파라미터 값 업데이트\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # 각 data batch에 대해 학습\n",
        "  # (image, labels): (입력 이미지, 정답 레이블)\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # to(device): 연산 수행 디바이스 설정\n",
        "    # images, labels, model간 연산을 위해.\n",
        "    images = images.to(device)  \n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "      print('Epoch: {}/{}, Batch Step: {}/{}, Loss: {:.4f}, Training Accuracy of the Current Batch: {}%'.\n",
        "            format(epoch + 1, num_epochs, i + 1, train_loader.__len__(), loss.item(), 100 * correct / batch_size))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10, Batch Step: 1000/3125, Loss: 1.6694, Training Accuracy of the Current Batch: 56.25%\n",
            "Epoch: 1/10, Batch Step: 2000/3125, Loss: 1.4801, Training Accuracy of the Current Batch: 50.0%\n",
            "Epoch: 1/10, Batch Step: 3000/3125, Loss: 1.2393, Training Accuracy of the Current Batch: 56.25%\n",
            "Epoch: 2/10, Batch Step: 1000/3125, Loss: 1.4334, Training Accuracy of the Current Batch: 43.75%\n",
            "Epoch: 2/10, Batch Step: 2000/3125, Loss: 0.8669, Training Accuracy of the Current Batch: 81.25%\n",
            "Epoch: 2/10, Batch Step: 3000/3125, Loss: 1.0446, Training Accuracy of the Current Batch: 56.25%\n",
            "Epoch: 3/10, Batch Step: 1000/3125, Loss: 1.0018, Training Accuracy of the Current Batch: 68.75%\n",
            "Epoch: 3/10, Batch Step: 2000/3125, Loss: 1.2166, Training Accuracy of the Current Batch: 56.25%\n",
            "Epoch: 3/10, Batch Step: 3000/3125, Loss: 0.5934, Training Accuracy of the Current Batch: 75.0%\n",
            "Epoch: 4/10, Batch Step: 1000/3125, Loss: 0.4379, Training Accuracy of the Current Batch: 81.25%\n",
            "Epoch: 4/10, Batch Step: 2000/3125, Loss: 0.3739, Training Accuracy of the Current Batch: 93.75%\n",
            "Epoch: 4/10, Batch Step: 3000/3125, Loss: 0.4969, Training Accuracy of the Current Batch: 81.25%\n",
            "Epoch: 5/10, Batch Step: 1000/3125, Loss: 0.7831, Training Accuracy of the Current Batch: 68.75%\n",
            "Epoch: 5/10, Batch Step: 2000/3125, Loss: 0.5861, Training Accuracy of the Current Batch: 75.0%\n",
            "Epoch: 5/10, Batch Step: 3000/3125, Loss: 0.4364, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 6/10, Batch Step: 1000/3125, Loss: 0.7567, Training Accuracy of the Current Batch: 81.25%\n",
            "Epoch: 6/10, Batch Step: 2000/3125, Loss: 0.7457, Training Accuracy of the Current Batch: 62.5%\n",
            "Epoch: 6/10, Batch Step: 3000/3125, Loss: 0.3570, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 7/10, Batch Step: 1000/3125, Loss: 0.1686, Training Accuracy of the Current Batch: 93.75%\n",
            "Epoch: 7/10, Batch Step: 2000/3125, Loss: 0.5812, Training Accuracy of the Current Batch: 81.25%\n",
            "Epoch: 7/10, Batch Step: 3000/3125, Loss: 0.7722, Training Accuracy of the Current Batch: 62.5%\n",
            "Epoch: 8/10, Batch Step: 1000/3125, Loss: 0.5106, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 8/10, Batch Step: 2000/3125, Loss: 1.3303, Training Accuracy of the Current Batch: 62.5%\n",
            "Epoch: 8/10, Batch Step: 3000/3125, Loss: 0.4961, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 9/10, Batch Step: 1000/3125, Loss: 0.2543, Training Accuracy of the Current Batch: 93.75%\n",
            "Epoch: 9/10, Batch Step: 2000/3125, Loss: 0.9764, Training Accuracy of the Current Batch: 56.25%\n",
            "Epoch: 9/10, Batch Step: 3000/3125, Loss: 0.4566, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 10/10, Batch Step: 1000/3125, Loss: 0.8959, Training Accuracy of the Current Batch: 62.5%\n",
            "Epoch: 10/10, Batch Step: 2000/3125, Loss: 0.5807, Training Accuracy of the Current Batch: 87.5%\n",
            "Epoch: 10/10, Batch Step: 3000/3125, Loss: 0.5128, Training Accuracy of the Current Batch: 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_6zPh3HmuIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f718445c-2bb5-46c3-f1c5-a2d5d07ad59d"
      },
      "source": [
        "model.eval()  # 모델 평가 모드로 변경 (모델 변수 고정 등)\n",
        "with torch.no_grad():  # 테스트 과정에서 gradient 계산 배제\n",
        "  total, correct = 0, 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Test Accuracy of the 10,000 Test Images: {}%'.format(100 * correct / total))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the 10,000 Test Images: 68.24%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}