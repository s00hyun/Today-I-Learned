{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 사전 훈련된 컨브넷 사용하기\n",
    "\n",
    "\n",
    "## 사전 훈련된 네트워크(pretrained network)\n",
    "\n",
    "* 작은 이미지 데이터셋에 딥러닝을 적용하는 일반적이고 매우 효과적인 방법은, **사전 훈련된 네트워크를 사용**하는 것이다.\n",
    "    * 사전 훈련된 네트워크(pretrained network) : 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크\n",
    "    * 사전 훈련된 네트워크에서 학습된 특성을 다른 문제에 적용하기 (딥러닝의 유연성)\n",
    "* **ImageNet 데이터셋에서 훈련된 대규모 컨브넷을 사용하자.**\n",
    "    * 강아지와 고양이 등의 많은 동물들을 포함\n",
    "* **+) VGG16 구조를 사용한다.**\n",
    "    * ImageNet 데이터셋에 널리 사용되는 간단한 컨브넷 구조\n",
    "\n",
    "## 사전 훈련된 네트워크를 사용하는 방법\n",
    "1. 특성 추출(feature extraction)\n",
    "2. 미세 조정(fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 특성 추출\n",
    "\n",
    "### 정의\n",
    "\n",
    "* **사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아내는 것**을 말한다.\n",
    "    * 이런 특성을 사용하여, 새로운 분류기를 처음부터 훈련한다.\n",
    "    \n",
    "### 합성곱 기반 층을 재사용하기\n",
    "\n",
    "* 컨브넷의 구조\n",
    "    * 연속된 합성곱과 풀링 층(= 합성곱 기반 층, convolutional base) + 완전 연결 분류기\n",
    "    * => **새로운 데이터를 사전 훈련된 네트워크의 합성곱 기반 층에 통과**시키고, **그 출력으로 새로운 분류기를 훈련**한다.\n",
    "* 합성곱 기반 층만 재사용!\n",
    "    * 분류기에서 학습한 표현은 모델이 훈련된 클래스 집합에 특화되어 있으므로\n",
    "    * 또한, 이미지에 있는 개체의 위치 정보는 분류기에 존재하지 않는다. (합성곱 기반 층에 존재함)\n",
    "* 특정 합성곱 층에서 추출한 표현의 일반성(& 재사용성) 수준은, 모델에 있는 층의 깊이에 달려 있다.\n",
    "    * 하위 층: 에지, 색깔, 질감 등 지역적이고 매우 일반적인 특성 맵을 추출\n",
    "    * ~> 상위 층: '강아지 눈'이나 '고양이 귀'와 같은 좀 더 추상적인 개념을 추출\n",
    "    * 새로운 데이터셋이 원본 모델이 훈련한 데이터셋과 많이 다르다면, 전체 합성곱 기반 층을 사용하기보다는 모델의 하위 층 몇 개만 특성 추출에 사용하는 것이 좋음\n",
    "    \n",
    "### 정리하자면,\n",
    "\n",
    "1.  **ImageNet 데이터셋에 훈련된 VGG16 네트워크의 합성곱 기반 층**을 사용해 강아지와 고양이 이미지에서 유용한 특성을 추출하자.\n",
    "    * VGG16 모델은 `keras.applications` 모듈에서 import 가능\n",
    "    \n",
    "2. **추출한 특성으로 강아지 vs. 고양이 분류기를 훈련**하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 15s 0us/step\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VGG16 합성곱 기반 층 만들기\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',  # 모델을 초기화할 가중치 체크포인트를 지정\n",
    "                 include_top=False,  # 네트워크의 최상위 완전 연결 분류기를 포함(default)할지 말지 결정\n",
    "                 input_shape=(150, 150, 3))  # 네트워크에 주입할 이미지 텐서의 크기 (선택사항 - 지정하지 않을 경우, 네트워크는 어떤 크기의 입력도 처리 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 층을 놓는 두 가지 방법\n",
    "\n",
    "1. 새로운 데이터셋에서 합성곱 기반 층을 실행하고, 출력을 numpy array로 디스크에 저장하여 이를 독립된 완전 연결 분류기의 입력으로 사용하기\n",
    "    * 모든 입력 이미지에 대해 합성곱 기반 층을 한 번만 실행하면 됨\n",
    "        * 빠르고, 적은 비용\n",
    "        * but 데이터 증식 사용 불가\n",
    "    \n",
    "\n",
    "2. 준비한 모델(conv_base) 위에 Dense 층을 쌓아 확장 -> 입력 데이터에서 end-to-end로 전체 모델 실행하기\n",
    "    * 모델에 노출된 모든 입력 이미지가 매번 합성곱 기반 층을 통과\n",
    "        * 데이터 증식 사용 가능\n",
    "        * but 비용 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 방식 : 데이터 증식을 사용하지 않는 빠른 특성 추출\n",
    "# 사전 훈련된 합성곱 기반 층을 사용한 특성 추출하기 \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './datasets/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)  # conv_base.predict : 이미지에서 특성 추출\n",
    "        features[i * batch_size : (i+1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count :\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.30939186e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.71357656e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.24061942e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.47217941e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.08376312e+00 ... 0.00000000e+00\n",
      "    7.87764847e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 7.96747327e-01 ... 8.09194863e-01\n",
      "    1.34273434e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.61687493e-01 ... 1.15642560e+00\n",
      "    1.62798071e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 8.48617911e-01 ... 4.70106900e-01\n",
      "    1.49155354e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.19635439e+00 ... 0.00000000e+00\n",
      "    4.56434488e-01 0.00000000e+00]\n",
      "   [7.83080608e-02 0.00000000e+00 1.41749144e+00 ... 0.00000000e+00\n",
      "    1.27010369e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.87891293e-01 ... 6.87951207e-01\n",
      "    1.55859995e+00 0.00000000e+00]\n",
      "   [1.90226138e-02 0.00000000e+00 1.67901665e-01 ... 4.26318258e-01\n",
      "    1.42155004e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.88732457e-01 0.00000000e+00]\n",
      "   [2.61459798e-02 0.00000000e+00 6.37175560e-01 ... 0.00000000e+00\n",
      "    1.05126560e-01 0.00000000e+00]\n",
      "   [1.46234855e-01 0.00000000e+00 2.64982998e-01 ... 0.00000000e+00\n",
      "    2.38740325e-01 0.00000000e+00]\n",
      "   [9.29081887e-02 0.00000000e+00 2.75309622e-01 ... 0.00000000e+00\n",
      "    1.89537466e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.59405637e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.03297234e+00 0.00000000e+00]\n",
      "   [1.22791290e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.25258684e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.87631643e-01 ... 0.00000000e+00\n",
      "    1.10997844e+00 0.00000000e+00]\n",
      "   [1.38475493e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.79106903e-01 0.00000000e+00]]\n",
      "\n",
      "  [[3.07327151e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.07576823e+00 0.00000000e+00]\n",
      "   [1.93561244e+00 0.00000000e+00 1.76412511e+00 ... 0.00000000e+00\n",
      "    8.23500335e-01 0.00000000e+00]\n",
      "   [5.62682569e-01 0.00000000e+00 3.33038497e+00 ... 0.00000000e+00\n",
      "    3.56817156e-01 0.00000000e+00]\n",
      "   [3.29855770e-01 0.00000000e+00 1.61313510e+00 ... 0.00000000e+00\n",
      "    9.03273284e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.72624350e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.46182132e-01 0.00000000e+00]\n",
      "   [1.60120249e+00 0.00000000e+00 1.88437653e+00 ... 0.00000000e+00\n",
      "    5.20837307e-03 0.00000000e+00]\n",
      "   [1.59118295e-01 0.00000000e+00 3.15110993e+00 ... 0.00000000e+00\n",
      "    3.03426504e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.55831981e+00 ... 0.00000000e+00\n",
      "    7.22453594e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.13734066e+00 0.00000000e+00]\n",
      "   [5.02343893e-01 0.00000000e+00 1.48044229e+00 ... 1.55236632e-01\n",
      "    6.51994050e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.60101461e+00 ... 3.49307582e-02\n",
      "    8.05441618e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 8.23215365e-01 ... 0.00000000e+00\n",
      "    6.86486125e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.85029852e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.91193569e-01 0.00000000e+00]\n",
      "   [1.63194430e+00 0.00000000e+00 5.18544555e-01 ... 0.00000000e+00\n",
      "    6.91527963e-01 0.00000000e+00]\n",
      "   [1.33269405e+00 0.00000000e+00 1.03944314e+00 ... 0.00000000e+00\n",
      "    7.44740725e-01 0.00000000e+00]\n",
      "   [8.68595958e-01 0.00000000e+00 9.39005733e-01 ... 0.00000000e+00\n",
      "    3.77848357e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.43378127e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.05522829e-01 0.00000000e+00]\n",
      "   [1.32325125e+00 0.00000000e+00 1.28896499e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.15061712e+00 0.00000000e+00 1.77534461e+00 ... 1.36303902e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.30680740e-01 0.00000000e+00 1.38665056e+00 ... 2.42124423e-02\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[8.25699568e-01 0.00000000e+00 3.17626595e-02 ... 0.00000000e+00\n",
      "    2.49825776e-01 0.00000000e+00]\n",
      "   [1.05953503e+00 0.00000000e+00 9.84019041e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.50644565e+00 0.00000000e+00 1.13340497e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.43378460e+00 0.00000000e+00 6.04575753e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[1.93320692e+00 0.00000000e+00 8.43632579e-01 ... 0.00000000e+00\n",
      "    5.83437443e-01 0.00000000e+00]\n",
      "   [2.00898576e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.68576920e-01 0.00000000e+00]\n",
      "   [6.98657930e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.81199896e-01 0.00000000e+00]\n",
      "   [7.97273040e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.70036495e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[3.81993324e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.12480474e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.28459960e-01 ... 0.00000000e+00\n",
      "    3.30973268e-01 0.00000000e+00]\n",
      "   [2.65783727e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.33701003e-01 0.00000000e+00]\n",
      "   [2.48645052e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.88609183e-01 0.00000000e+00]]\n",
      "\n",
      "  [[2.76403159e-01 0.00000000e+00 6.43484235e-01 ... 0.00000000e+00\n",
      "    6.51881993e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.03273392e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.44114494e+00 0.00000000e+00 1.07673693e+00 ... 0.00000000e+00\n",
      "    2.23842889e-01 0.00000000e+00]\n",
      "   [1.09699988e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.00088298e-01 0.00000000e+00]]\n",
      "\n",
      "  [[3.94634426e-01 0.00000000e+00 8.12514126e-01 ... 0.00000000e+00\n",
      "    6.55910134e-01 0.00000000e+00]\n",
      "   [1.23824403e-01 0.00000000e+00 2.19400835e+00 ... 0.00000000e+00\n",
      "    3.03520203e-01 0.00000000e+00]\n",
      "   [1.17690420e+00 0.00000000e+00 1.39530420e+00 ... 0.00000000e+00\n",
      "    5.52578866e-01 4.79790568e-02]\n",
      "   [8.64890099e-01 0.00000000e+00 2.20033288e-01 ... 0.00000000e+00\n",
      "    1.03203714e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 9.34350669e-01 ... 0.00000000e+00\n",
      "    3.50554585e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.18564785e+00 ... 1.57151908e-01\n",
      "    5.12730896e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 9.90906119e-01 ... 2.86012143e-03\n",
      "    4.87295866e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.90441209e-01 ... 1.01557918e-01\n",
      "    9.19345737e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.67764151e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.46362138e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.16337371e-01 0.00000000e+00]\n",
      "   [1.43453121e-01 0.00000000e+00 1.60163283e+00 ... 0.00000000e+00\n",
      "    5.86774349e-02 0.00000000e+00]\n",
      "   [3.15117002e-01 0.00000000e+00 1.33247209e+00 ... 0.00000000e+00\n",
      "    2.23420978e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.01438165e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.63614309e-01 ... 0.00000000e+00\n",
      "    6.27093911e-01 0.00000000e+00]\n",
      "   [3.74211252e-01 0.00000000e+00 2.02052855e+00 ... 5.15018344e-01\n",
      "    0.00000000e+00 1.93029583e-01]\n",
      "   [3.59144717e-01 0.00000000e+00 1.77882528e+00 ... 1.33447126e-01\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.52581263e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.13258612e+00 ... 3.90921235e-01\n",
      "    6.95936799e-01 2.95664549e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.80552483e+00 ... 9.28827345e-01\n",
      "    0.00000000e+00 6.55842662e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.59396219e+00 ... 4.67499644e-01\n",
      "    2.46455193e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.26901758e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.40190029e+00 ... 1.06268600e-01\n",
      "    7.12116539e-01 0.00000000e+00]\n",
      "   [2.71003664e-01 0.00000000e+00 2.62558484e+00 ... 3.88004512e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.85780036e-01 0.00000000e+00 2.41171575e+00 ... 2.12257445e-01\n",
      "    1.71041757e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[7.02942610e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.89924312e-01 0.00000000e+00]\n",
      "   [2.33127013e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.83258677e-01 0.00000000e+00]\n",
      "   [5.52813560e-02 0.00000000e+00 1.44267082e+00 ... 0.00000000e+00\n",
      "    4.14393395e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.08540869e+00 ... 0.00000000e+00\n",
      "    4.11025167e-01 0.00000000e+00]]\n",
      "\n",
      "  [[4.88376915e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.81481469e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.10572845e-01 ... 0.00000000e+00\n",
      "    2.86198795e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.51051140e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 3.11930478e-01]\n",
      "   [2.12465107e-01 0.00000000e+00 3.01302743e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 2.39300936e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.10268116e-01 ... 0.00000000e+00\n",
      "    6.94608927e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.58583373e-01 ... 0.00000000e+00\n",
      "    5.60918689e-01 0.00000000e+00]\n",
      "   [2.34403089e-01 0.00000000e+00 1.40639186e+00 ... 0.00000000e+00\n",
      "    1.00116134e-02 1.44592181e-01]\n",
      "   [2.76579201e-01 0.00000000e+00 1.58479261e+00 ... 0.00000000e+00\n",
      "    6.33619428e-02 0.00000000e+00]]\n",
      "\n",
      "  [[1.37791380e-01 0.00000000e+00 1.29610837e-01 ... 0.00000000e+00\n",
      "    5.53159714e-01 0.00000000e+00]\n",
      "   [7.00703263e-03 0.00000000e+00 3.70019019e-01 ... 0.00000000e+00\n",
      "    2.35663593e-01 0.00000000e+00]\n",
      "   [5.34120202e-03 0.00000000e+00 1.08996284e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.16356272e-02 0.00000000e+00 1.11914539e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n",
      "*****\n",
      "[0. 1. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)\n",
    "print('*****')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4, 4, 512)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 분류기에 주입하기 위해 (samples, 8192) 크기로 펼치기\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8192)\n",
      "(1000, 8192)\n",
      "(1000, 8192)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.6278 - acc: 0.6670 - val_loss: 0.4642 - val_acc: 0.8250\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 2s 894us/step - loss: 0.4467 - acc: 0.7925 - val_loss: 0.3787 - val_acc: 0.8500\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 2s 894us/step - loss: 0.3720 - acc: 0.8395 - val_loss: 0.3455 - val_acc: 0.8510\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.3272 - acc: 0.8655 - val_loss: 0.3079 - val_acc: 0.8810\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 2s 877us/step - loss: 0.2924 - acc: 0.8740 - val_loss: 0.2922 - val_acc: 0.8770\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 2s 857us/step - loss: 0.2729 - acc: 0.8870 - val_loss: 0.2815 - val_acc: 0.8980\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 2s 884us/step - loss: 0.2565 - acc: 0.8975 - val_loss: 0.2695 - val_acc: 0.8900\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.2446 - acc: 0.9015 - val_loss: 0.2624 - val_acc: 0.9000\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.2293 - acc: 0.9075 - val_loss: 0.2578 - val_acc: 0.8920\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 2s 863us/step - loss: 0.2113 - acc: 0.9185 - val_loss: 0.2519 - val_acc: 0.8980\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 2s 867us/step - loss: 0.1985 - acc: 0.9200 - val_loss: 0.2569 - val_acc: 0.8920\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.1835 - acc: 0.9320 - val_loss: 0.2530 - val_acc: 0.8940\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 2s 880us/step - loss: 0.1812 - acc: 0.9350 - val_loss: 0.2450 - val_acc: 0.8990\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 2s 885us/step - loss: 0.1777 - acc: 0.9330 - val_loss: 0.2472 - val_acc: 0.9000\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.1700 - acc: 0.9405 - val_loss: 0.2401 - val_acc: 0.9010\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 2s 867us/step - loss: 0.1646 - acc: 0.9380 - val_loss: 0.2380 - val_acc: 0.9040\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 2s 870us/step - loss: 0.1571 - acc: 0.9440 - val_loss: 0.2396 - val_acc: 0.9010\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 2s 866us/step - loss: 0.1458 - acc: 0.9500 - val_loss: 0.2448 - val_acc: 0.9020\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 2s 862us/step - loss: 0.1370 - acc: 0.9535 - val_loss: 0.2376 - val_acc: 0.9030\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 2s 830us/step - loss: 0.1334 - acc: 0.9535 - val_loss: 0.2358 - val_acc: 0.9060\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 2s 856us/step - loss: 0.1274 - acc: 0.9570 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 2s 864us/step - loss: 0.1307 - acc: 0.9545 - val_loss: 0.2332 - val_acc: 0.9000\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 2s 858us/step - loss: 0.1245 - acc: 0.9600 - val_loss: 0.2341 - val_acc: 0.9010\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 2s 856us/step - loss: 0.1199 - acc: 0.9605 - val_loss: 0.2356 - val_acc: 0.9040\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 2s 868us/step - loss: 0.1119 - acc: 0.9620 - val_loss: 0.2408 - val_acc: 0.9040\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 2s 846us/step - loss: 0.1106 - acc: 0.9625 - val_loss: 0.2415 - val_acc: 0.8970\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 2s 845us/step - loss: 0.1022 - acc: 0.9700 - val_loss: 0.2353 - val_acc: 0.9010\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 2s 857us/step - loss: 0.1045 - acc: 0.9670 - val_loss: 0.2361 - val_acc: 0.9000\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 2s 856us/step - loss: 0.0932 - acc: 0.9710 - val_loss: 0.2383 - val_acc: 0.9010\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 2s 858us/step - loss: 0.0940 - acc: 0.9680 - val_loss: 0.2374 - val_acc: 0.9020\n"
     ]
    }
   ],
   "source": [
    "# 완전 연결 분류기를 정의하고 훈련하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs=30,\n",
    "                   batch_size=20,\n",
    "                   validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 해석\n",
    "\n",
    "* 약 90%의 검증 정확도에 도달\n",
    "* 이전의 작은 모델보다는 향상되었으나, \n",
    "* 많은 비율로 드롭아웃했음에도 불구하고 훈련을 시작하면서 거의 바로 과대적합됨\n",
    "    * 과대적합을 막기 위해 필수적인 데이터 증식을 사용하지 않았기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 증식을 사용한 특성 추출\n",
    "\n",
    "* 훨씬 느리고 비용이 많이 들지만,\n",
    "* 훈련하는 동안 데이터 증식 기법을 사용할 수 있다.\n",
    "    * 과대적합을 줄일 수 있음\n",
    "* conv_base 모델을 확장하고, 입력 데이터를 사용하여 end-to-end로 실행한다.\n",
    "* 연산 비용이 크므로, GPU를 사용할 수 있을 때 시도해야 한다.\n",
    "    * 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 미세 조정(fine-tuning)\n",
    "\n",
    "### 정의\n",
    "\n",
    "* 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해제하고, 모델에 새로 추가한 층과 함께 훈련하는 것을 말한다.\n",
    "    * 특성 추출을 보완\n",
    "    * 여기에서 새로 추가된 층은 완전 연결 분류기\n",
    "* 주어진 문제에 조금 더 밀접하게 재사용 모델의 표현을 일부 조정하기 때문에, 미세 조정이라고 부른다.\n",
    "\n",
    "### 네트워크를 미세 조정하는 단계\n",
    "\n",
    "1. 사전에 훈련된 기반 네트워크 위에 새로운 네트워크를 추가\n",
    "\n",
    "2. 기반 네트워크를 동결\n",
    "\n",
    "3. 새로 추가한 네트워크를 훈련\n",
    "\n",
    "**4. 기반 네트워크에서, 일부 층의 동결을 해제**\n",
    "\n",
    "**5. 동결을 해제한 층과 새로 추가한 층을 함께 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미세 조정 대상\n",
    "\n",
    "* block5_conv1, block5_conv2, block5_conv3\n",
    "    * 이전 층들은 동결됨\n",
    "    * 여기에서는 **구체적인 특성을 인코딩하는 상위 층을 미세 조정하는 것이 효과적**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_ste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 층까지 모든 층 동결하기\n",
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-eaa8c8e1f219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     validation_steps=50)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)"
     ]
    }
   ],
   "source": [
    "# 모델 미세 조정하기\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
