{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 사전 훈련된 컨브넷 사용하기\n",
    "\n",
    "\n",
    "## 사전 훈련된 네트워크(pretrained network)\n",
    "\n",
    "* 작은 이미지 데이터셋에 딥러닝을 적용하는 일반적이고 매우 효과적인 방법은, **사전 훈련된 네트워크를 사용**하는 것이다.\n",
    "    * 사전 훈련된 네트워크(pretrained network) : 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크\n",
    "    * 사전 훈련된 네트워크에서 학습된 특성을 다른 문제에 적용하기 (딥러닝의 유연성)\n",
    "* **ImageNet 데이터셋에서 훈련된 대규모 컨브넷을 사용하자.**\n",
    "    * 강아지와 고양이 등의 많은 동물들을 포함\n",
    "* **+) VGG16 구조를 사용한다.**\n",
    "    * ImageNet 데이터셋에 널리 사용되는 간단한 컨브넷 구조\n",
    "\n",
    "## 사전 훈련된 네트워크를 사용하는 방법\n",
    "1. 특성 추출(feature extraction)\n",
    "2. 미세 조정(fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 특성 추출\n",
    "\n",
    "### 정의\n",
    "\n",
    "* **사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아내는 것**을 말한다.\n",
    "    * 이런 특성을 사용하여, 새로운 분류기를 처음부터 훈련한다.\n",
    "    \n",
    "### 합성곱 기반 층을 재사용하기\n",
    "\n",
    "* 컨브넷의 구조\n",
    "    * 연속된 합성곱과 풀링 층(= 합성곱 기반 층, convolutional base) + 완전 연결 분류기\n",
    "    * => **새로운 데이터를 사전 훈련된 네트워크의 합성곱 기반 층에 통과**시키고, **그 출력으로 새로운 분류기를 훈련**한다.\n",
    "* 합성곱 기반 층만 재사용!\n",
    "    * 분류기에서 학습한 표현은 모델이 훈련된 클래스 집합에 특화되어 있으므로\n",
    "    * 또한, 이미지에 있는 개체의 위치 정보는 분류기에 존재하지 않는다. (합성곱 기반 층에 존재함)\n",
    "* 특정 합성곱 층에서 추출한 표현의 일반성(& 재사용성) 수준은, 모델에 있는 층의 깊이에 달려 있다.\n",
    "    * 하위 층: 에지, 색깔, 질감 등 지역적이고 매우 일반적인 특성 맵을 추출\n",
    "    * ~> 상위 층: '강아지 눈'이나 '고양이 귀'와 같은 좀 더 추상적인 개념을 추출\n",
    "    * 새로운 데이터셋이 원본 모델이 훈련한 데이터셋과 많이 다르다면, 전체 합성곱 기반 층을 사용하기보다는 모델의 하위 층 몇 개만 특성 추출에 사용하는 것이 좋음\n",
    "    \n",
    "### 정리하자면,\n",
    "\n",
    "1.  **ImageNet 데이터셋에 훈련된 VGG16 네트워크의 합성곱 기반 층**을 사용해 강아지와 고양이 이미지에서 유용한 특성을 추출하자.\n",
    "    * VGG16 모델은 `keras.applications` 모듈에서 import 가능\n",
    "    \n",
    "2. **추출한 특성으로 강아지 vs. 고양이 분류기를 훈련**하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VGG16 합성곱 기반 층 만들기\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',  # 모델을 초기화할 가중치 체크포인트를 지정\n",
    "                 include_top=False,  # 네트워크의 최상위 완전 연결 분류기를 포함(default)할지 말지 결정\n",
    "                 input_shape=(150, 150, 3))  # 네트워크에 주입할 이미지 텐서의 크기 (선택사항 - 지정하지 않을 경우, 네트워크는 어떤 크기의 입력도 처리 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 층을 놓는 두 가지 방법\n",
    "\n",
    "1. 새로운 데이터셋에서 합성곱 기반 층을 실행하고, 출력을 numpy array로 디스크에 저장하여 이를 독립된 완전 연결 분류기의 입력으로 사용하기\n",
    "    * 모든 입력 이미지에 대해 합성곱 기반 층을 한 번만 실행하면 됨\n",
    "        * 빠르고, 적은 비용\n",
    "        * but 데이터 증식 사용 불가\n",
    "    \n",
    "\n",
    "2. 준비한 모델(conv_base) 위에 Dense 층을 쌓아 확장 -> 입력 데이터에서 end-to-end로 전체 모델 실행하기\n",
    "    * 모델에 노출된 모든 입력 이미지가 매번 합성곱 기반 층을 통과\n",
    "        * 데이터 증식 사용 가능\n",
    "        * but 비용 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 방식 : 데이터 증식을 사용하지 않는 빠른 특성 추출\n",
    "# 사전 훈련된 합성곱 기반 층을 사용한 특성 추출하기 \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './datasets/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)  # conv_base.predict : 이미지에서 특성 추출\n",
    "        features[i * batch_size : (i+1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count :\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.00660014e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.12165117e-01 0.00000000e+00]\n",
      "   [4.82690394e-01 0.00000000e+00 8.64712119e-01 ... 0.00000000e+00\n",
      "    1.75862908e-02 0.00000000e+00]\n",
      "   [7.27159560e-01 0.00000000e+00 7.37299562e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.46535873e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.45096838e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.46938694e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.84431422e+00 0.00000000e+00 2.03542352e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.18293428e+00 0.00000000e+00 1.78556371e+00 ... 0.00000000e+00\n",
      "    3.82368118e-01 0.00000000e+00]\n",
      "   [6.56298995e-01 0.00000000e+00 5.85007966e-01 ... 0.00000000e+00\n",
      "    5.31171441e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.02003825e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.09453321e+00 0.00000000e+00 1.12351692e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.43866372e-01 0.00000000e+00 1.00002944e+00 ... 0.00000000e+00\n",
      "    2.35477984e-01 0.00000000e+00]\n",
      "   [1.15007617e-01 0.00000000e+00 6.80213809e-01 ... 0.00000000e+00\n",
      "    7.30250537e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.44236839e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.48915553e-01 0.00000000e+00 8.88566852e-01 ... 0.00000000e+00\n",
      "    9.13659930e-02 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.74014783e-01 ... 0.00000000e+00\n",
      "    1.77513778e-01 0.00000000e+00]\n",
      "   [5.59796095e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.58803451e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.01838923e+00 0.00000000e+00]\n",
      "   [9.79874194e-01 0.00000000e+00 4.66888189e-01 ... 0.00000000e+00\n",
      "    1.60217917e+00 0.00000000e+00]\n",
      "   [1.04866886e+00 0.00000000e+00 3.25886041e-01 ... 0.00000000e+00\n",
      "    1.57763171e+00 0.00000000e+00]\n",
      "   [7.70525634e-01 0.00000000e+00 1.74826205e-01 ... 0.00000000e+00\n",
      "    8.06252062e-01 0.00000000e+00]]\n",
      "\n",
      "  [[7.73789883e-01 0.00000000e+00 6.27191961e-01 ... 0.00000000e+00\n",
      "    9.05187845e-01 0.00000000e+00]\n",
      "   [1.44420254e+00 0.00000000e+00 1.45770645e+00 ... 1.19319052e-01\n",
      "    7.14544475e-01 0.00000000e+00]\n",
      "   [1.36213994e+00 0.00000000e+00 1.86409760e+00 ... 1.20173059e-01\n",
      "    8.78886998e-01 0.00000000e+00]\n",
      "   [8.20864081e-01 0.00000000e+00 2.23214364e+00 ... 0.00000000e+00\n",
      "    5.51578045e-01 0.00000000e+00]]\n",
      "\n",
      "  [[7.13926077e-01 0.00000000e+00 3.60073984e-01 ... 0.00000000e+00\n",
      "    4.13765579e-01 0.00000000e+00]\n",
      "   [1.42839181e+00 0.00000000e+00 1.02805150e+00 ... 0.00000000e+00\n",
      "    2.68161833e-01 0.00000000e+00]\n",
      "   [1.24884880e+00 0.00000000e+00 1.91466689e+00 ... 0.00000000e+00\n",
      "    4.04698521e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.25920630e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[5.44396877e-01 0.00000000e+00 2.52723694e-02 ... 0.00000000e+00\n",
      "    1.70812786e-01 0.00000000e+00]\n",
      "   [1.48045993e+00 0.00000000e+00 2.77408421e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.48499167e+00 0.00000000e+00 1.00103927e+00 ... 0.00000000e+00\n",
      "    2.82394260e-01 0.00000000e+00]\n",
      "   [1.10194981e+00 0.00000000e+00 1.18304873e+00 ... 0.00000000e+00\n",
      "    1.13137901e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.15210325e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.24588501e-01 0.00000000e+00]\n",
      "   [1.05900836e+00 0.00000000e+00 1.37460661e+00 ... 0.00000000e+00\n",
      "    5.98099887e-01 0.00000000e+00]\n",
      "   [1.05757022e+00 0.00000000e+00 2.89999843e+00 ... 0.00000000e+00\n",
      "    4.08830345e-01 0.00000000e+00]\n",
      "   [8.36835742e-01 0.00000000e+00 2.63885593e+00 ... 0.00000000e+00\n",
      "    6.31097019e-01 0.00000000e+00]]\n",
      "\n",
      "  [[2.16190696e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.82103384e-01 0.00000000e+00]\n",
      "   [8.67918372e-01 0.00000000e+00 1.65648150e+00 ... 3.71778384e-02\n",
      "    6.15447581e-01 0.00000000e+00]\n",
      "   [5.92497706e-01 2.82369256e-02 2.67972422e+00 ... 9.32689384e-02\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.19958147e-01 0.00000000e+00 2.15171051e+00 ... 1.03520676e-01\n",
      "    2.70866990e-01 0.00000000e+00]]\n",
      "\n",
      "  [[2.76587754e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.37397277e-01 0.00000000e+00]\n",
      "   [2.60685086e-02 3.93478870e-02 9.93684053e-01 ... 0.00000000e+00\n",
      "    1.03319287e+00 0.00000000e+00]\n",
      "   [4.52396274e-03 1.00762546e-01 1.86496544e+00 ... 1.04725853e-01\n",
      "    3.53846967e-01 0.00000000e+00]\n",
      "   [2.88608611e-01 0.00000000e+00 1.64561653e+00 ... 0.00000000e+00\n",
      "    3.22568148e-01 0.00000000e+00]]\n",
      "\n",
      "  [[3.17670673e-01 0.00000000e+00 2.87098289e-02 ... 0.00000000e+00\n",
      "    7.86733627e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.47276157e-01 ... 0.00000000e+00\n",
      "    1.28171659e+00 0.00000000e+00]\n",
      "   [1.44330516e-01 0.00000000e+00 2.84815282e-01 ... 0.00000000e+00\n",
      "    1.29902601e+00 0.00000000e+00]\n",
      "   [9.14334118e-01 0.00000000e+00 5.33382833e-01 ... 0.00000000e+00\n",
      "    9.77911532e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.31162745e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.54241395e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.19562209e-01 0.00000000e+00]\n",
      "   [2.57230937e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.85158169e-01 0.00000000e+00]]\n",
      "\n",
      "  [[3.92598361e-02 0.00000000e+00 3.87107283e-01 ... 0.00000000e+00\n",
      "    3.77433121e-01 0.00000000e+00]\n",
      "   [3.00652981e-01 0.00000000e+00 7.17047215e-01 ... 0.00000000e+00\n",
      "    2.69926488e-01 0.00000000e+00]\n",
      "   [6.68524146e-01 0.00000000e+00 7.20883012e-01 ... 0.00000000e+00\n",
      "    9.07242894e-02 0.00000000e+00]\n",
      "   [6.54101610e-01 0.00000000e+00 2.81776577e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 1.37217253e-01]]\n",
      "\n",
      "  [[2.27187499e-01 0.00000000e+00 5.97871125e-01 ... 0.00000000e+00\n",
      "    5.99088490e-01 0.00000000e+00]\n",
      "   [5.78083575e-01 0.00000000e+00 1.21850276e+00 ... 7.06380457e-02\n",
      "    6.96455836e-01 0.00000000e+00]\n",
      "   [1.00962710e+00 0.00000000e+00 1.10828424e+00 ... 8.18116844e-01\n",
      "    7.60988057e-01 0.00000000e+00]\n",
      "   [6.22728705e-01 0.00000000e+00 9.28629220e-01 ... 6.84123755e-01\n",
      "    7.49062061e-01 2.76016265e-01]]\n",
      "\n",
      "  [[3.82387102e-01 0.00000000e+00 5.23164928e-01 ... 0.00000000e+00\n",
      "    7.30160952e-01 0.00000000e+00]\n",
      "   [4.52086508e-01 0.00000000e+00 1.09232771e+00 ... 3.11101109e-01\n",
      "    7.12438583e-01 0.00000000e+00]\n",
      "   [5.51598191e-01 0.00000000e+00 9.19996858e-01 ... 7.59279609e-01\n",
      "    8.94587874e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.51829600e-01 ... 6.08992875e-01\n",
      "    9.55092549e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 4.74573940e-01 ... 0.00000000e+00\n",
      "    8.07054281e-01 0.00000000e+00]\n",
      "   [4.30269957e-01 0.00000000e+00 9.53885078e-01 ... 0.00000000e+00\n",
      "    4.89550531e-01 0.00000000e+00]\n",
      "   [7.52259135e-01 0.00000000e+00 9.37576056e-01 ... 5.40569946e-02\n",
      "    3.19101214e-01 0.00000000e+00]\n",
      "   [3.85419071e-01 0.00000000e+00 9.32559371e-01 ... 3.01152587e-01\n",
      "    7.24385500e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.56291437e+00 ... 0.00000000e+00\n",
      "    8.23624969e-01 0.00000000e+00]\n",
      "   [6.50134921e-01 0.00000000e+00 1.49817634e+00 ... 3.42485696e-01\n",
      "    4.15148139e-02 0.00000000e+00]\n",
      "   [9.44732845e-01 0.00000000e+00 1.04516101e+00 ... 1.69577509e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [8.32175493e-01 0.00000000e+00 5.69801509e-01 ... 4.30816382e-01\n",
      "    3.34908485e-01 0.00000000e+00]]\n",
      "\n",
      "  [[4.99800265e-01 0.00000000e+00 1.19421244e+00 ... 0.00000000e+00\n",
      "    5.52112222e-01 0.00000000e+00]\n",
      "   [8.02556038e-01 0.00000000e+00 1.03529382e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.37094736e+00 0.00000000e+00 1.55974805e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.32468104e+00 0.00000000e+00 8.70731831e-01 ... 0.00000000e+00\n",
      "    7.47080445e-02 0.00000000e+00]]\n",
      "\n",
      "  [[6.66539788e-01 0.00000000e+00 1.27185249e+00 ... 0.00000000e+00\n",
      "    1.72684550e-01 0.00000000e+00]\n",
      "   [9.75730479e-01 0.00000000e+00 8.68418396e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [8.61437678e-01 0.00000000e+00 2.73379236e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.34439743e-01 0.00000000e+00 1.09178436e+00 ... 0.00000000e+00\n",
      "    2.61299610e-02 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.61618143e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.13796806e+00 0.00000000e+00]\n",
      "   [1.19878948e-01 0.00000000e+00 1.76491231e-01 ... 0.00000000e+00\n",
      "    1.19486046e+00 0.00000000e+00]\n",
      "   [3.97937298e-02 0.00000000e+00 8.31568241e-03 ... 2.53804654e-01\n",
      "    1.29830432e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.26305968e-03\n",
      "    1.48456645e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 2.13166863e-01 ... 0.00000000e+00\n",
      "    1.13180470e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 8.97389174e-01 ... 2.90775567e-01\n",
      "    1.47352028e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.09481895e+00 ... 8.11337650e-01\n",
      "    1.41866398e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.11892629e+00 ... 6.45087957e-01\n",
      "    7.87617564e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.30246848e-01 ... 0.00000000e+00\n",
      "    1.10979009e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.02141285e+00 ... 0.00000000e+00\n",
      "    8.23083758e-01 0.00000000e+00]\n",
      "   [1.18076198e-01 0.00000000e+00 1.34171867e+00 ... 0.00000000e+00\n",
      "    4.48754787e-01 0.00000000e+00]\n",
      "   [6.92639470e-01 0.00000000e+00 1.53014874e+00 ... 0.00000000e+00\n",
      "    1.63007468e-01 0.00000000e+00]]\n",
      "\n",
      "  [[7.59000361e-01 0.00000000e+00 1.87670827e-01 ... 0.00000000e+00\n",
      "    1.16911161e+00 0.00000000e+00]\n",
      "   [8.09876144e-01 0.00000000e+00 1.00751221e+00 ... 0.00000000e+00\n",
      "    8.76336932e-01 0.00000000e+00]\n",
      "   [5.46908379e-01 0.00000000e+00 1.02342224e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.01954365e+00 0.00000000e+00 1.05175757e+00 ... 0.00000000e+00\n",
      "    2.56635547e-01 0.00000000e+00]]]]\n",
      "*****\n",
      "[1. 0. 1. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)\n",
    "print('*****')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4, 4, 512)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 분류기에 주입하기 위해 (samples, 8192) 크기로 펼치기\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8192)\n",
      "(1000, 8192)\n",
      "(1000, 8192)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/shchoi/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5834 - acc: 0.6790 - val_loss: 0.4325 - val_acc: 0.8540\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 2s 908us/step - loss: 0.4246 - acc: 0.8165 - val_loss: 0.3594 - val_acc: 0.8660\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 2s 910us/step - loss: 0.3457 - acc: 0.8580 - val_loss: 0.3201 - val_acc: 0.8810\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 2s 923us/step - loss: 0.3095 - acc: 0.8750 - val_loss: 0.3015 - val_acc: 0.8830\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 2s 956us/step - loss: 0.2856 - acc: 0.8835 - val_loss: 0.2813 - val_acc: 0.8940\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 2s 951us/step - loss: 0.2501 - acc: 0.9050 - val_loss: 0.2768 - val_acc: 0.8880\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 2s 937us/step - loss: 0.2471 - acc: 0.9065 - val_loss: 0.2708 - val_acc: 0.8900\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 2s 919us/step - loss: 0.2308 - acc: 0.9105 - val_loss: 0.2562 - val_acc: 0.8980\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 2s 929us/step - loss: 0.2183 - acc: 0.9165 - val_loss: 0.2525 - val_acc: 0.9030\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 2s 923us/step - loss: 0.2098 - acc: 0.9215 - val_loss: 0.2529 - val_acc: 0.8970\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 2s 928us/step - loss: 0.2015 - acc: 0.9260 - val_loss: 0.2527 - val_acc: 0.8910\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 2s 947us/step - loss: 0.1851 - acc: 0.9300 - val_loss: 0.2431 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 2s 933us/step - loss: 0.1720 - acc: 0.9385 - val_loss: 0.2409 - val_acc: 0.9030\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 2s 938us/step - loss: 0.1717 - acc: 0.9355 - val_loss: 0.2396 - val_acc: 0.9040\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 2s 915us/step - loss: 0.1654 - acc: 0.9435 - val_loss: 0.2407 - val_acc: 0.9010\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 2s 914us/step - loss: 0.1581 - acc: 0.9430 - val_loss: 0.2376 - val_acc: 0.9050\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 2s 950us/step - loss: 0.1523 - acc: 0.9470 - val_loss: 0.2367 - val_acc: 0.9070\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 2s 954us/step - loss: 0.1448 - acc: 0.9510 - val_loss: 0.2366 - val_acc: 0.9060\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 2s 928us/step - loss: 0.1388 - acc: 0.9485 - val_loss: 0.2405 - val_acc: 0.9020\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 2s 951us/step - loss: 0.1323 - acc: 0.9570 - val_loss: 0.2354 - val_acc: 0.9050\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 2s 967us/step - loss: 0.1303 - acc: 0.9505 - val_loss: 0.2347 - val_acc: 0.9080\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 2s 943us/step - loss: 0.1162 - acc: 0.9645 - val_loss: 0.2373 - val_acc: 0.9040\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 2s 924us/step - loss: 0.1144 - acc: 0.9665 - val_loss: 0.2375 - val_acc: 0.9040\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 2s 934us/step - loss: 0.1138 - acc: 0.9630 - val_loss: 0.2352 - val_acc: 0.9060\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 2s 904us/step - loss: 0.1104 - acc: 0.9605 - val_loss: 0.2369 - val_acc: 0.9050\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 2s 915us/step - loss: 0.1042 - acc: 0.9645 - val_loss: 0.2371 - val_acc: 0.9040\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 2s 917us/step - loss: 0.0949 - acc: 0.9735 - val_loss: 0.2394 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 2s 912us/step - loss: 0.0950 - acc: 0.9690 - val_loss: 0.2376 - val_acc: 0.9050\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 2s 904us/step - loss: 0.0939 - acc: 0.9685 - val_loss: 0.2367 - val_acc: 0.9060\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 2s 927us/step - loss: 0.0876 - acc: 0.9675 - val_loss: 0.2482 - val_acc: 0.9010\n"
     ]
    }
   ],
   "source": [
    "# 완전 연결 분류기를 정의하고 훈련하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs=30,\n",
    "                   batch_size=20,\n",
    "                   validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 66us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_features, test_labels, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [0.2581778594106436, 0.8909999930858612]\n"
     ]
    }
   ],
   "source": [
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Generate predictions for 10 samples\n",
      "predictions shape: (10, 1)\n",
      "[[4.9094170e-02]\n",
      " [9.4886434e-01]\n",
      " [9.9999630e-01]\n",
      " [2.5522161e-01]\n",
      " [4.9181312e-02]\n",
      " [3.4788817e-02]\n",
      " [9.9999863e-01]\n",
      " [5.8899540e-01]\n",
      " [4.5769107e-01]\n",
      " [1.1756823e-04]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Generate predictions for 10 samples')\n",
    "predictions = model.predict(test_features[:10])\n",
    "print('predictions shape:', predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.28598529 ... 0.         0.8517803  0.        ]\n",
      " [0.         0.         0.         ... 0.         0.60926491 0.        ]\n",
      " [0.36326131 0.         1.03963172 ... 0.         0.4551124  0.        ]\n",
      " ...\n",
      " [1.26883686 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.1952025  0.         0.         ... 0.         0.51773065 0.        ]\n",
      " [0.11173177 0.         0.         ... 0.         0.5490033  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict_classes(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=1.0, Predicted=[1]\n",
      "Expected=0.0, Predicted=[0]\n",
      "Expected=0.0, Predicted=[0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_labels)):\n",
    "    print(\"Expected=%s, Predicted=%s\" % (test_labels[i], ynew[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 해석\n",
    "\n",
    "* 약 90%의 검증 정확도에 도달\n",
    "* 이전의 작은 모델보다는 향상되었으나, \n",
    "* 많은 비율로 드롭아웃했음에도 불구하고 훈련을 시작하면서 거의 바로 과대적합됨\n",
    "    * 과대적합을 막기 위해 필수적인 데이터 증식을 사용하지 않았기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 증식을 사용한 특성 추출\n",
    "\n",
    "* 훨씬 느리고 비용이 많이 들지만,\n",
    "* 훈련하는 동안 데이터 증식 기법을 사용할 수 있다.\n",
    "    * 과대적합을 줄일 수 있음\n",
    "* conv_base 모델을 확장하고, 입력 데이터를 사용하여 end-to-end로 실행한다.\n",
    "* 연산 비용이 크므로, GPU를 사용할 수 있을 때 시도해야 한다.\n",
    "    * 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 미세 조정(fine-tuning)\n",
    "\n",
    "### 정의\n",
    "\n",
    "* 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해제하고, 모델에 새로 추가한 층과 함께 훈련하는 것을 말한다.\n",
    "    * 특성 추출을 보완\n",
    "    * 여기에서 새로 추가된 층은 완전 연결 분류기\n",
    "* 주어진 문제에 조금 더 밀접하게 재사용 모델의 표현을 일부 조정하기 때문에, 미세 조정이라고 부른다.\n",
    "\n",
    "### 네트워크를 미세 조정하는 단계\n",
    "\n",
    "1. 사전에 훈련된 기반 네트워크 위에 새로운 네트워크를 추가\n",
    "\n",
    "2. 기반 네트워크를 동결\n",
    "\n",
    "3. 새로 추가한 네트워크를 훈련\n",
    "\n",
    "**4. 기반 네트워크에서, 일부 층의 동결을 해제**\n",
    "\n",
    "**5. 동결을 해제한 층과 새로 추가한 층을 함께 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미세 조정 대상\n",
    "\n",
    "* block5_conv1, block5_conv2, block5_conv3\n",
    "    * 이전 층들은 동결됨\n",
    "    * 여기에서는 **구체적인 특성을 인코딩하는 상위 층을 미세 조정하는 것이 효과적**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_ste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 층까지 모든 층 동결하기\n",
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-eaa8c8e1f219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     validation_steps=50)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Today-I-Learned/ML-DL/venv/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)"
     ]
    }
   ],
   "source": [
    "# 모델 미세 조정하기\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
